# TriSense
This is the official codebase of <b><a href='https://arxiv.org/pdf/2505.18110'>Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM</a></b>. This repo is under construction.
![af355688748a212818b4746797e6731](https://github.com/user-attachments/assets/fbc89818-b878-4efe-b72c-959f35db169e)
## TODO List
- [ ] Release dataset
- [ ] Release checkpoints & inference code
- [ ] Release trainining code
- [ ] Huggingface demo
- [ ] Post-training on highher quality and more data
