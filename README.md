# TriSense
This is the official code base of <b><a href='https://arxiv.org/pdf/2505.18110'>Watch and Listen: Understanding Audio-Visual-Speech Moments with Multimodal LLM</a></b>. This repo is under construction:
## TODO List
- [ ] Release dataset
- [ ] Release checkpoints & inference code
- [ ] Release trainining code
- [ ] Huggingface demo
- [ ] Finetune on highher quality and more data
